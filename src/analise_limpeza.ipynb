{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141a9aef",
   "metadata": {},
   "source": [
    "### Objetivo do Projeto\n",
    "\n",
    "Este notebook realiza o processo completo de ETL (Extração, Transformação e Carga) para limpar, padronizar e unificar as bases de dados de clientes da **Empresa Confidencial**.\n",
    "\n",
    "**Objetivo:** Atribuir um ID único da `Base_Referencia` a todos os clientes das demais bases, utilizando *fuzzy matching* para lidar com inconsistências de nomes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21fd3cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: Error importing numpy: you should not try to import numpy from\n        its source directory; please exit the numpy source tree, and relaunch\n        your python interpreter from there.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Bibliotecas\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfuzzywuzzy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m process\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Felipe\\Desktop\\CURSO DNC\\PROJETO BANCO DE DADOS BECORP\\.venv\\Lib\\site-packages\\pandas\\__init__.py:31\u001b[39m\n\u001b[32m     28\u001b[39m         _missing_dependencies.append(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_dependency\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_e\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _missing_dependencies:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     32\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnable to import required dependencies:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(_missing_dependencies)\n\u001b[32m     33\u001b[39m     )\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     37\u001b[39m     \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: Unable to import required dependencies:\nnumpy: Error importing numpy: you should not try to import numpy from\n        its source directory; please exit the numpy source tree, and relaunch\n        your python interpreter from there."
     ]
    }
   ],
   "source": [
    "# Aqui, importamos todas as bibliotecas que serão usadas no projeto.\n",
    "import pandas as pd\n",
    "import re\n",
    "from fuzzywuzzy import process\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10283ff",
   "metadata": {},
   "source": [
    "## Funções de Apoio\n",
    "\n",
    "Nesta seção, definimos as funções que nos ajudarão a limpar os nomes dos clientes e a encontrar as correspondências. Manter a lógica em funções torna o código mais limpo e reutilizável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdba46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula das Funções\n",
    "\n",
    "def limpar_nome_cliente(nome_original):\n",
    "    \"\"\"\n",
    "    Aplica as regras de limpeza e padronização nos nomes dos clientes,\n",
    "    seguindo as diretrizes definidas no projeto.\n",
    "    \"\"\"\n",
    "    if not isinstance(nome_original, str):\n",
    "        return \"\"\n",
    "\n",
    "    nome_processado = nome_original.upper()\n",
    "\n",
    "    # Regra Específica: Trata o caso \"MDS – FASTSHOP\"\n",
    "    if 'MDS' in nome_processado and 'FASTSHOP' in nome_processado:\n",
    "        return 'FASTSHOP'\n",
    "\n",
    "    # Regra Geral: Para nomes com hífen (Ex: \"CARGILL - BARREIRAS\"),\n",
    "    # pega apenas a parte antes do hífen.\n",
    "    if '-' in nome_processado:\n",
    "        nome_processado = nome_processado.split('-')[0].strip()\n",
    "\n",
    "    # Regra de Limpeza: Remove apenas as aspas (duplas e simples)\n",
    "    nome_processado = nome_processado.replace('\"', '').replace(\"'\", \"\")\n",
    "    \n",
    "    # Remove espaços em branco extras\n",
    "    nome_processado = \" \".join(nome_processado.split())\n",
    "    \n",
    "    return nome_processado\n",
    "\n",
    "def encontrar_correspondencia(nome_cliente, lista_nomes_referencia, limite_pontuacao=85):\n",
    "    \"\"\"\n",
    "    Compara um nome de cliente com a lista de referência e encontra o mais parecido,\n",
    "    respeitando um limite mínimo de pontuação.\n",
    "    \"\"\"\n",
    "    if not nome_cliente or not lista_nomes_referencia:\n",
    "        return None, 0\n",
    "        \n",
    "    melhor_correspondecia, pontuacao = process.extractOne(nome_cliente, lista_nomes_referencia)\n",
    "    \n",
    "    if pontuacao >= limite_pontuacao:\n",
    "        return melhor_correspondecia, pontuacao\n",
    "    else:\n",
    "        return None, pontuacao\n",
    "\n",
    "print(\"Funções 'limpar_nome_cliente' e 'encontrar_correspondencia' definidas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5098391f",
   "metadata": {},
   "source": [
    "## Passo 1: Definição de Caminhos e Estrutura de Pastas\n",
    "\n",
    "Definimos onde os dados brutos estão e onde o resultado final será salvo. O script também cria a pasta de destino caso ela não exista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula de Configuração de Caminhos\n",
    "\n",
    "caminho_dados_brutos = os.path.join('Data', 'Raw')\n",
    "caminho_dados_processados = os.path.join('Data', 'Processed')\n",
    "nome_arquivo_excel = 'Base de Dados Clientes.xlsx'\n",
    "caminho_completo_excel = os.path.join(caminho_dados_brutos, nome_arquivo_excel)\n",
    "\n",
    "# Cria a pasta de saída \"Data/Processed\" se ela não existir\n",
    "os.makedirs(caminho_dados_processados, exist_ok=True)\n",
    "caminho_arquivo_saida = os.path.join(caminho_dados_processados, \"base_unificada_clientes_beecorp.csv\")\n",
    "\n",
    "print(f\"Caminho do arquivo de entrada: {caminho_completo_excel}\")\n",
    "print(f\"Caminho do arquivo de saída: {caminho_arquivo_saida}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874a1e8b",
   "metadata": {},
   "source": [
    "## Passo 2: Extração (E) - Carregamento dos Dados\n",
    "\n",
    "Lemos os dados a partir das abas do arquivo Excel para a memória, utilizando a biblioteca Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef5deee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando a base: Departamento_Pessoal\n",
      "   -> Padronização de clientes concluída.\n",
      "\n",
      "Processando a base: Operacoes\n",
      "   -> Padronização de clientes concluída.\n",
      "\n",
      "Processando a base: Profissional_Ponta\n",
      "   -> Padronização de clientes concluída.\n",
      "\n",
      "Processando a base: Recrutamento_Selecao\n",
      "   -> Padronização de clientes concluída.\n",
      "\n",
      "--- Processo de Unificação Concluído ---\n",
      "Total de registros na base unificada: 2281\n",
      "Total de clientes únicos padronizados: 10\n",
      "Base de dados unificada salva em: ../Data/Processed/base_padronizada_final.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Célula de Carregamento dos Dados\n",
    "\n",
    "try:\n",
    "    nome_aba_referencia = 'Base_Referencia'\n",
    "    nomes_abas_clientes = [\n",
    "        'Recrutamento_Selecao', 'Profissional_Ponta',\n",
    "        'Operacoes', 'Departamento_Pessoal'\n",
    "    ]\n",
    "\n",
    "    base_referencia = pd.read_excel(caminho_completo_excel, sheet_name=nome_aba_referencia)\n",
    "\n",
    "    lista_dfs_clientes = [\n",
    "        pd.read_excel(caminho_completo_excel, sheet_name=nome_aba) for nome_aba in nomes_abas_clientes\n",
    "    ]\n",
    "    print(\"Todas as abas do Excel foram carregadas com sucesso!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro ao carregar o arquivo: {e}\")\n",
    "\n",
    "# Visualiza as primeiras 5 linhas da base de referência para verificação\n",
    "base_referencia.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e82de5f",
   "metadata": {},
   "source": [
    "## Passo 3: Transformação (T) - Limpeza e Unificação\n",
    "\n",
    "Esta é a etapa principal do processo. Aqui, nós:\n",
    "1.  Juntamos todos os nomes de clientes em uma lista única.\n",
    "2.  Preparamos a base de referência.\n",
    "3.  Aplicamos a limpeza e o *fuzzy matching* para encontrar as correspondências.\n",
    "4.  Fazemos o `merge` (join) para unificar os dados e atribuir os IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ae592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula de Transformação e Processamento\n",
    "\n",
    "# 1. Juntar todos os clientes em uma lista única\n",
    "todos_os_clientes = pd.concat([df[\"Nome do Cliente\"] for df in lista_dfs_clientes])\n",
    "clientes_unicos = pd.DataFrame(todos_os_clientes.unique(), columns=['Nome Original']).dropna()\n",
    "print(f\"Encontrados {len(clientes_unicos)} nomes de clientes únicos.\")\n",
    "\n",
    "# 2. Preparar a base de referência\n",
    "base_referencia['Razão Social Limpa'] = base_referencia['Razão Social'].apply(limpar_nome_cliente)\n",
    "lista_referencia = base_referencia['Razão Social Limpa'].unique().tolist()\n",
    "print(\"Base de referência preparada.\")\n",
    "\n",
    "# 3. Limpar nomes e encontrar correspondências\n",
    "clientes_unicos['Nome Limpo'] = clientes_unicos['Nome Original'].apply(limpar_nome_cliente)\n",
    "resultados_match = clientes_unicos['Nome Limpo'].apply(\n",
    "    lambda nome: pd.Series(encontrar_correspondencia(nome, lista_referencia), index=['Match Encontrado', 'Pontuacao'])\n",
    ")\n",
    "clientes_unicos_com_match = pd.concat([clientes_unicos, resultados_match], axis=1)\n",
    "print(\"Processo de fuzzy matching concluído.\")\n",
    "\n",
    "# 4. Unificar com a base de referência\n",
    "base_unificada = pd.merge(\n",
    "    clientes_unicos_com_match, base_referencia,\n",
    "    left_on='Match Encontrado', right_on='Razão Social Limpa',\n",
    "    how='left'\n",
    ")\n",
    "print(\"Merge finalizado.\")\n",
    "\n",
    "# Visualiza as primeiras linhas do resultado com as pontuações\n",
    "base_unificada.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95122d8",
   "metadata": {},
   "source": [
    "## Passo 4: Carga (L) - Organização e Salvamento\n",
    "\n",
    "Na etapa final, selecionamos as colunas mais importantes, organizamos o resultado e salvamos em um novo arquivo CSV na pasta `Data/Processed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f41fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula de Salvamento\n",
    "\n",
    "# 1. Organizar colunas\n",
    "base_final_organizada = base_unificada[[\n",
    "    'Nome Original', 'Nome Limpo', 'Razão Social', 'Pontuacao',\n",
    "    'ID', 'Unidade', 'Empresa / Grupo Economico'\n",
    "]]\n",
    "\n",
    "# 2. Salvar em CSV\n",
    "base_final_organizada.to_csv(caminho_arquivo_saida, index=False, encoding='utf-8-sig')\n",
    "\n",
    "# 3. Análise final\n",
    "total_clientes = len(base_final_organizada)\n",
    "clientes_com_id = base_final_organizada['ID'].notna().sum()\n",
    "percentual_sucesso = (clientes_com_id / total_clientes) * 100 if total_clientes > 0 else 0\n",
    "\n",
    "print(\"--- Análise de Resultados ---\")\n",
    "print(f\"Processo concluído com sucesso!\")\n",
    "print(f\"Total de clientes únicos processados: {total_clientes}\")\n",
    "print(f\"Clientes que receberam um ID: {clientes_com_id}\")\n",
    "print(f\"Taxa de sucesso na unificação: {percentual_sucesso:.2f}%\")\n",
    "print(f\"\\nArquivo final salvo em: {caminho_arquivo_saida}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
